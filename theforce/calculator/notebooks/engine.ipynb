{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ase.neighborlist import NeighborList\n",
    "from ase.calculators.calculator import Calculator, all_changes\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from theforce.util.util import iterable\n",
    "\n",
    "\n",
    "class Engine(Calculator):\n",
    "    implemented_properties = ['energy', 'forces']\n",
    "    default_parameters = {'rc': None}\n",
    "\n",
    "    def __init__(self, terms=None, ** kwargs):\n",
    "        Calculator.__init__(self, **kwargs)\n",
    "        if self.parameters.rc is None:\n",
    "            raise NotImplementedError('pass a cutoff!')\n",
    "        self.terms = iterable(terms)\n",
    "        self.params = [par for term in self.terms for par in term.parameters()]\n",
    "        self.as_tensors_with_grads = False\n",
    "\n",
    "    def calculate(self, atoms=None, properties=['energy'], system_changes=all_changes):\n",
    "        Calculator.calculate(self, atoms, properties, system_changes)\n",
    "\n",
    "        natoms = len(self.atoms)\n",
    "        if 'numbers' in system_changes:\n",
    "            rc = self.parameters.rc\n",
    "            self.nl = NeighborList([rc / 2] * natoms, self_interaction=False,\n",
    "                                   bothways=True)\n",
    "        self.nl.update(self.atoms)\n",
    "\n",
    "        xyz = torch.tensor(self.atoms.positions, requires_grad=True)\n",
    "        nums = self.atoms.numbers\n",
    "        cell = self.atoms.cell\n",
    "        energy = 0.0\n",
    "        for a in range(natoms):\n",
    "            neighbors, offsets = self.nl.get_neighbors(a)\n",
    "            cells = torch.from_numpy(np.dot(offsets, cell))\n",
    "            r = xyz[neighbors] + cells - xyz[a]\n",
    "            for pot in self.terms:\n",
    "                energy = energy + pot(nums[a], nums[neighbors], r)\n",
    "        forces, = grad(-energy, xyz, create_graph=self.as_tensors_with_grads)\n",
    "\n",
    "        if self.as_tensors_with_grads:\n",
    "            xyz.detach_()\n",
    "        else:\n",
    "            energy = energy.detach().numpy().reshape(1)[0]\n",
    "            forces = forces.detach().numpy()\n",
    "\n",
    "        self.results['energy'] = energy\n",
    "        self.results['forces'] = forces\n",
    "\n",
    "\n",
    "def _input(systems):\n",
    "    energies = torch.tensor([atoms.get_potential_energy()\n",
    "                             for atoms in systems])\n",
    "    forces = torch.cat([torch.tensor(atoms.get_forces())\n",
    "                        for atoms in systems]).view(-1)\n",
    "    return torch.cat([energies, forces])\n",
    "\n",
    "\n",
    "def _target(eng, systems):\n",
    "    energies = []\n",
    "    forces = []\n",
    "    for atoms in systems:\n",
    "        eng.calculate(atoms)\n",
    "        energies += [eng.results['energy']]\n",
    "        forces += [eng.results['forces']]\n",
    "    energies = torch.tensor(energies).view(-1)\n",
    "    forces = torch.cat(forces).view(-1)\n",
    "    return torch.cat([energies, forces])\n",
    "\n",
    "\n",
    "def train_engine(eng, systems, loss_function=torch.nn.MSELoss(), steps=10, lr=0.1):\n",
    "    if not hasattr(eng, 'optimizer'):\n",
    "        eng.optimizer = torch.optim.Adam(eng.params, lr=lr)\n",
    "\n",
    "    input = _input(systems)\n",
    "    for _ in range(steps):\n",
    "        def closure():\n",
    "            eng.optimizer.zero_grad()\n",
    "            target = _target(eng, systems)\n",
    "            loss = loss_function(input, target)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        eng.optimizer.step(closure)\n",
    "    print('trained for {} steps, and loss is {}'.format(steps, closure()))\n",
    "    eng.optimizer.zero_grad()\n",
    "\n",
    "\n",
    "def example():\n",
    "    #from theforce.calculator.engine import Engine\n",
    "    from torch.nn import Module, Parameter\n",
    "\n",
    "    class LJ(Module):\n",
    "\n",
    "        def __init__(self,):\n",
    "            super().__init__()\n",
    "            self.eps = Parameter(torch.tensor(1.0), requires_grad=False)\n",
    "            self.sigma = Parameter(torch.tensor(1.0), requires_grad=False)\n",
    "\n",
    "        def forward(self, a, aa, r):\n",
    "            x = (self.sigma**2/(r**2).sum(dim=-1))\n",
    "            return 4*self.eps*(x**6 - x**3).sum()/2\n",
    "\n",
    "        def extra_repr(self):\n",
    "            print(self.eps)\n",
    "            print(self.sigma)\n",
    "\n",
    "    from ase import Atoms\n",
    "    from ase.optimize import BFGS\n",
    "\n",
    "    atoms = Atoms('ArAr', positions=[[0, 0, 0], [2., 0, 0]], cell=[\n",
    "                  9., 9., 9.], pbc=True)\n",
    "    calc = Engine(rc=3.0, terms=LJ())\n",
    "    atoms.set_calculator(calc)\n",
    "    BFGS(atoms).run(fmax=1e-5)\n",
    "    dmin = ((atoms.positions[0]-atoms.positions[1])**2).sum()\n",
    "    print('isclose: {} (diff = {})'.format(\n",
    "        np.isclose(dmin, 2**(1./3)), dmin-2**(1./3)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
