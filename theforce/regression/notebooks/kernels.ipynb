{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "from theforce.regression.algebra import positive, free_form\n",
    "import warnings\n",
    "\n",
    "\n",
    "class RBF(Module):\n",
    "    \"\"\"\n",
    "    Parameters: scale, variance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale, variance):\n",
    "        super(RBF, self).__init__()\n",
    "        self._scale = Parameter(free_form(scale))\n",
    "        self._variance = Parameter(free_form(variance))\n",
    "\n",
    "    def cov_matrix(self, x, xx, d_dtheta=None, wrt=0, sumd=True):\n",
    "        \"\"\"\n",
    "        It returns K if d_dtheta=None.\n",
    "        If d_dtheta is given it means that some derivative should be \n",
    "        calculated. \"theta\" could be x, xx, or sth else.\n",
    "        If d_dtheta = ones_like(x) and wrt=0 (ones_like(xx) and wrt=1)\n",
    "        it returns dK/dx (dK/dxx).\n",
    "        If d_dtheta has a dimensionality greater than 2 it means that \n",
    "        it holds derivative of x (or xx depending on wrt) wrt sth else.\n",
    "        Then, it will return dK/dtheta.\n",
    "        It will sum over the features dimension if sumd=True.\n",
    "        \"\"\"\n",
    "        assert wrt == 0 or wrt == 1\n",
    "        scale = positive(self._scale)\n",
    "        r = (x[:, None, ] - xx[None, ]) / scale\n",
    "        cov = (-(r**2).sum(dim=-1)/2).exp() * self.diag()\n",
    "        if d_dtheta is not None:\n",
    "            r = r / scale\n",
    "            for _ in range(d_dtheta.dim()-2):\n",
    "                r = torch.unsqueeze(r, -1)\n",
    "                cov = torch.unsqueeze(cov, -1)\n",
    "            _derivative = (r*torch.unsqueeze(d_dtheta, dim=1-wrt)\n",
    "                           ) * (-(-1)**(wrt))\n",
    "            if sumd:\n",
    "                cov = cov * _derivative.sum(dim=2)\n",
    "            else:\n",
    "                cov = torch.unsqueeze(cov, dim=2) * _derivative\n",
    "        return cov\n",
    "\n",
    "    def matrices(self, x, xx, d_dx=False, d_dxx=False, d_dxdxx=False):\n",
    "\n",
    "        # covariance matrix\n",
    "        iscale = 1.0/positive(self._scale)\n",
    "        r = (x[:, None, ] - xx[None, ]) * iscale\n",
    "        cov = (-(r**2).sum(dim=-1)/2).exp() * self.diag()\n",
    "\n",
    "        # derivatives\n",
    "        _dx = _dxx = _dxdxx = None\n",
    "        if d_dx or d_dxx or d_dxdxx:\n",
    "            rr = (r*iscale)\n",
    "        if d_dx or d_dxx:\n",
    "            cov_r = cov[..., None] * rr\n",
    "\n",
    "        if d_dx:\n",
    "            _dx = -cov_r\n",
    "        if d_dxx:\n",
    "            _dxx = cov_r\n",
    "        if d_dxdxx:\n",
    "            rirj = -rr[..., None] * rr[..., None, :]\n",
    "            d = torch.LongTensor(torch.arange(iscale.size()[0]))\n",
    "            rirj[..., d, d] = rirj[..., d, d] + iscale**2\n",
    "            _dxdxx = rirj * cov[..., None, None]\n",
    "\n",
    "        return cov, _dx, _dxx, _dxdxx\n",
    "\n",
    "    def diag(self):\n",
    "        return positive(self._variance)\n",
    "\n",
    "    def diag_derivatives(self, d_dtheta):\n",
    "        warnings.warn(\n",
    "            'diag_derivatives in RBF is deprecated! It may be incorrect!')\n",
    "        scale = positive(self._scale)\n",
    "        for _ in range(d_dtheta.dim()-2):\n",
    "            scale = torch.unsqueeze(scale, -1)\n",
    "        return ((d_dtheta / scale)**2).sum() * self.diag()\n",
    "\n",
    "    def extra_repr(self):\n",
    "        print('\\nRBF parameters: \\nscale: {}\\nvariance: {}\\n'.format(\n",
    "            positive(self._scale).data, positive(self._variance).data))\n",
    "\n",
    "\n",
    "class Cauchy(Module):\n",
    "\n",
    "    def __init__(self, scale, variance):\n",
    "        super(Cauchy, self).__init__()\n",
    "        self._scale = Parameter(free_form(scale))\n",
    "        self._variance = Parameter(free_form(variance))\n",
    "\n",
    "    def matrices(self, x, xx, d_dx=False, d_dxx=False, d_dxdxx=False):\n",
    "        # covariance matrix\n",
    "        scale = positive(self._scale)\n",
    "        r = (x[:, None, ]-xx[None, ])/scale\n",
    "        cov = 1.0/(1.0+(r**2).sum(dim=-1))\n",
    "\n",
    "        # derivatives\n",
    "        _dx = _dxx = _dxdxx = None\n",
    "        if d_dx or d_dxx:\n",
    "            a = (-2*r*cov[..., None]**2/scale) * self.diag()\n",
    "            if d_dx:\n",
    "                _dx = a\n",
    "            if d_dxx:\n",
    "                _dxx = -a\n",
    "\n",
    "        if d_dxdxx:\n",
    "            _dxdxx = -(8*r[..., None, :]*r[..., None]*cov[..., None, None] - 2*torch.eye(scale.size(0))\n",
    "                       )*cov[..., None, None]**2/(scale[None, ]*scale[:, None]) * self.diag()\n",
    "            \n",
    "        cov = self.diag()*cov\n",
    "        return cov, _dx, _dxx, _dxdxx\n",
    "\n",
    "    def diag(self):\n",
    "        return positive(self._variance)\n",
    "\n",
    "\n",
    "def test_if_works():\n",
    "    from theforce.regression.algebra import jitcholesky\n",
    "    variance = torch.tensor(1.0)\n",
    "    scale = torch.ones(7)\n",
    "    kern = RBF(scale, variance)\n",
    "    X = torch.rand(1000, 7)\n",
    "    K = kern.cov_matrix(X, X)\n",
    "    L, ridge = jitcholesky(K)\n",
    "    print('ridge for cholesky decomposition: {}\\n'.format(ridge))\n",
    "    print(kern, '\\n')\n",
    "\n",
    "    #\n",
    "    X1 = torch.rand(19, 7)\n",
    "    X2 = torch.rand(33, 7)\n",
    "    dX = torch.rand(33, 7, 3)\n",
    "    K = kern.cov_matrix(X1, X2, d_dtheta=dX, wrt=1, sumd=False)\n",
    "    print(K.shape)\n",
    "    dX = torch.ones_like(X1)\n",
    "    K = kern.cov_matrix(X1, X2, d_dtheta=dX, wrt=0, sumd=False)\n",
    "    print(K.shape)\n",
    "\n",
    "    a, b, c, d = kern.matrices(X1, X2, True, True, True)\n",
    "    print([p.shape for p in [a, b, c, d]])\n",
    "    \n",
    "    #--------------------------------------\n",
    "    kern = Cauchy(scale, variance)\n",
    "    a, b, c, d = kern.matrices(X1, X2, True, True, True)\n",
    "    print([p.shape for p in [a, b, c, d]])\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_if_works()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
