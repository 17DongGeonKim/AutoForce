{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "import torch\n",
    "_2pi = torch.tensor(2*pi)\n",
    "\n",
    "\n",
    "# general ---------------------------------------\n",
    "def positive(x):\n",
    "    return torch.log(1. + torch.exp(x))\n",
    "\n",
    "\n",
    "def free_form(x):\n",
    "    return torch.log(torch.exp(x) - 1.)\n",
    "\n",
    "\n",
    "def sum_packed_dim(packed, sizes, dim=-1):\n",
    "    result = torch.stack([piece.sum(dim=dim)\n",
    "                          for piece in torch.split(packed, sizes, dim=dim)], dim=dim)\n",
    "    return result\n",
    "\n",
    "\n",
    "# decompositions ---------------------------------------------\n",
    "def jitcholesky(A, jit=1e-6, jitbase=2):\n",
    "    ridge = 0\n",
    "    try:\n",
    "        L = torch.cholesky(A)\n",
    "    except RuntimeError:\n",
    "        scale = A.diag().mean()\n",
    "        ridge = jit*scale\n",
    "        done = False\n",
    "        while not done:\n",
    "            try:\n",
    "                L = torch.cholesky(A + ridge*torch.eye(\n",
    "                    *A.size(), dtype=A.dtype))\n",
    "                done = True\n",
    "            except RuntimeError:\n",
    "                ridge *= jitbase\n",
    "            if ridge > scale:\n",
    "                raise RuntimeError('cholesky was not successful!')\n",
    "    return L, ridge\n",
    "\n",
    "\n",
    "def low_rank_factor(K, Y, logdet=False, solve=False, jit=1e-6, jitbase=2):\n",
    "    \"\"\"\n",
    "    Inputs: Y, K\n",
    "    K: a symmetric positive definite (covariance) matrix,\n",
    "       this will be factored  as K = L @ L.t()\n",
    "    Y: 1D or 2D\n",
    "    Returns: Q, logdet, ridge\n",
    "    ------------------------------------------------------\n",
    "    The following equality holds:\n",
    "    Q.t() @ Q = Y.t() @ K.inverse() @ Y\n",
    "    \"\"\"\n",
    "    L, ridge = jitcholesky(K, jit=jit, jitbase=jitbase)\n",
    "    if len(Y.size()) == 1:\n",
    "        _1d, _Y = True, Y.view(-1, 1)\n",
    "    else:\n",
    "        _1d, _Y = False, Y\n",
    "    if solve:\n",
    "        Q, _ = torch.triangular_solve(_Y, L, upper=False)\n",
    "    else:\n",
    "        Q = torch.mm(L.inverse(), _Y)\n",
    "    if logdet:\n",
    "        ld = 2*L.diag().log().sum()\n",
    "    else:\n",
    "        ld = None\n",
    "    return Q, ld, ridge\n",
    "\n",
    "\n",
    "def log_normal(Y, K, solve=True):\n",
    "    Q, logdet, ridge = low_rank_factor(K, Y, logdet=True, solve=solve)\n",
    "    return -(torch.mm(Q.t(), Q) + logdet + torch.log(_2pi)*Y.size(0))/2\n",
    "\n",
    "\n",
    "def solve_svd(A, Y):\n",
    "    U, S, V = torch.svd(A)\n",
    "    return V @ ((U.t() @ Y)/S)\n",
    "\n",
    "\n",
    "# greedy algorithms ------------------------------------------------------------\n",
    "def select_greedy_simple(T, num, Z=None):\n",
    "    assert T.dim() == 2\n",
    "    X = T\n",
    "    if Z is None:\n",
    "        arg = torch.randint(X.shape[0], (1,))\n",
    "        Z = X[arg]\n",
    "        X = torch.cat([X[:arg], X[arg+1:]])\n",
    "        #selected = [arg]\n",
    "        n = num-1\n",
    "    else:\n",
    "        assert Z.dim() == 2\n",
    "        #selected = []\n",
    "        n = num\n",
    "    for _ in range(n):\n",
    "        val, arg = torch.max(((X[:, None]-Z[None])**2).sum(dim=(1, 2)), 0)\n",
    "        #selected += [arg]\n",
    "        Z = torch.cat([Z, X[arg][None]])\n",
    "        X = torch.cat([X[:arg], X[arg+1:]])\n",
    "    return Z\n",
    "\n",
    "\n",
    "# examples ---------------------------------------------------------------------\n",
    "def example_sum_packed_dim():\n",
    "    sizes = torch.randint(1, 10, (100,))\n",
    "    Y = [torch.ones(7, size) for size in sizes]\n",
    "    Y = torch.cat(Y, dim=1)\n",
    "    P = sum_packed_dim(Y, sizes.tolist())\n",
    "    #print(Y.size(), P.size())\n",
    "    print('sum_packed_dim works: {}'.format(P.size() == torch.Size([7, 100])))\n",
    "\n",
    "\n",
    "# tests ------------------------------------------------------------------------\n",
    "def test(n=1000):\n",
    "\n",
    "    # test cholesky\n",
    "    K = torch.ones(n, n)\n",
    "    L, ridge = jitcholesky(K)\n",
    "    test_cholesky = torch.allclose(torch.mm(L, L.t()), K)\n",
    "    print('Cholesky: {}'.format(test_cholesky))\n",
    "\n",
    "    # test log_normal\n",
    "    Y = torch.rand(n)\n",
    "    dist = torch.distributions.MultivariateNormal(torch.zeros(n), scale_tril=L)\n",
    "    test_log_normal = torch.allclose(dist.log_prob(Y), log_normal(Y, K))\n",
    "    print('log_normal: {}'.format(test_log_normal))\n",
    "\n",
    "    # test select_greedy\n",
    "    X = torch.rand(100, 7)\n",
    "    Z = select_greedy_simple(X, 17)\n",
    "    Z = select_greedy_simple(X, 17, Z=Z)\n",
    "\n",
    "    # test solve SVD\n",
    "    A = torch.diag(torch.ones(10))\n",
    "    Y = torch.linspace(0, 100, 10)\n",
    "    X = solve_svd(A, Y)\n",
    "    test_solve_svd = torch.allclose(X, Y)\n",
    "    print('solve_svd: {}'.format(test_solve_svd))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    example_sum_packed_dim()\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
