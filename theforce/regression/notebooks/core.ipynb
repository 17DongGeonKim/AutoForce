{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" experimental \"\"\"\n",
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "from theforce.regression.algebra import free_form, positive\n",
    "\n",
    "\n",
    "class Displacement(Module):\n",
    "\n",
    "    def __init__(self, dim=1):\n",
    "        super().__init__()\n",
    "        self._scale = Parameter(free_form(torch.ones(dim)))\n",
    "\n",
    "    def forward(self, x=None, xx=None):\n",
    "        if xx is None and x is None:\n",
    "            return torch.ones(0, 0, self._scale.size(0))\n",
    "        elif x is None:\n",
    "            x = xx\n",
    "        elif xx is None:\n",
    "            xx = x\n",
    "        return (x[:, None]-xx[None])/positive(self._scale)\n",
    "\n",
    "    def delta(self):\n",
    "        return torch.eye(self._scale.size(0))\n",
    "\n",
    "    def divide(self, operation):\n",
    "        if operation is 'func':\n",
    "            return 1.0\n",
    "        else:\n",
    "            scale = positive(self._scale)\n",
    "            if operation is 'grad':\n",
    "                return scale\n",
    "            elif operation is 'hessian':\n",
    "                return scale[None]*scale[:, None]\n",
    "\n",
    "    def extra_repr(self):\n",
    "        print('length scales: {}'.format(positive(self._scale)))\n",
    "\n",
    "\n",
    "class Stationary(Module):\n",
    "    \"\"\" [dim=1, signal=1] \"\"\"\n",
    "\n",
    "    def __init__(self, dim=1, signal=1.0):\n",
    "        super().__init__()\n",
    "        self.r = Displacement(dim=dim)\n",
    "        self._signal = Parameter(free_form(torch.as_tensor(signal)))\n",
    "        self.params = [self.r._scale, self._signal]\n",
    "\n",
    "    def forward(self, x=None, xx=None, operation='func'):\n",
    "        return positive(self._signal).pow(2)*getattr(self, operation)(self.r(x=x, xx=xx)) \\\n",
    "            / self.r.divide(operation)\n",
    "\n",
    "    def diag(self, x=None):\n",
    "        if x is None:\n",
    "            return positive(self._signal).pow(2)\n",
    "        else:\n",
    "            return positive(self._signal).pow(2)*torch.ones(x.size(0))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        print('signal variance: {}'.format(positive(self._signal).pow(2)))\n",
    "\n",
    "\n",
    "class SquaredExp(Stationary):\n",
    "    \"\"\" [dim=1, signal=1] \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def func(self, r):\n",
    "        return (-(r**2).sum(dim=-1)/2).exp()\n",
    "\n",
    "    def grad(self, r):\n",
    "        cov = self.func(r)\n",
    "        return -r*cov[..., None]\n",
    "\n",
    "    def hessian(self, r):\n",
    "        cov = self.func(r)\n",
    "        return (r[..., None, :]*r[..., None]-self.r.delta())*cov[..., None, None]\n",
    "\n",
    "\n",
    "class White(Stationary):\n",
    "\n",
    "    def __init__(self, signal=1e-3, **kwargs):\n",
    "        super().__init__(signal=signal, **kwargs)\n",
    "        self._signal.requires_grad = False\n",
    "\n",
    "    def forward(self, x=None, xx=None):\n",
    "        x_in = x is not None\n",
    "        xx_in = xx is not None\n",
    "        if not x_in and not xx_in:\n",
    "            return self.diag()\n",
    "        elif x_in and not xx_in:\n",
    "            return self.diag(x).diag()\n",
    "        elif xx_in and not x_in:\n",
    "            return self.diag(xx).diag()\n",
    "        elif x_in and xx_in:\n",
    "            if x.shape == xx.shape and torch.allclose(x, xx):\n",
    "                return self.diag(x).diag()\n",
    "            else:\n",
    "                return torch.zeros(x.size(0), xx.size(0))\n",
    "\n",
    "\n",
    "def test():\n",
    "    if 1:\n",
    "        dim = 7\n",
    "        kern = SquaredExp(dim=dim)\n",
    "        x = torch.rand(19, dim)\n",
    "        xx = torch.rand(37, dim)\n",
    "        K = kern(x=x, xx=xx)\n",
    "        assert torch.allclose(K, (-(x[:, None]-xx[None])**2/2)\n",
    "                              .sum(dim=-1).exp())\n",
    "        print(kern(x, xx, 'func').shape)\n",
    "        print(kern(x, xx, 'grad').shape)\n",
    "        print(kern(x, xx, 'hessian').shape)\n",
    "\n",
    "    if 1:\n",
    "        white = White(signal=1.0)\n",
    "        x = torch.rand(7, 1)\n",
    "        assert (white(x, x) == torch.eye(7)).all()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
