{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "from theforce.regression.algebra import free_form, positive\n",
    "\n",
    "\n",
    "class Displacement(Module):\n",
    "\n",
    "    def __init__(self, dim=1):\n",
    "        super().__init__()\n",
    "        self._scale = Parameter(free_form(torch.ones(dim)))\n",
    "\n",
    "    def forward(self, x=None, xx=None):\n",
    "        if xx is None and x is None:\n",
    "            return torch.ones(0, 0, self._scale.size(0))\n",
    "        elif x is None:\n",
    "            x = xx\n",
    "        elif xx is None:\n",
    "            xx = x\n",
    "        return (x[:, None]-xx[None])/positive(self._scale)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        print('length scales: {}'.format(positive(self._scale)))\n",
    "\n",
    "\n",
    "class PNorm(Module):\n",
    "\n",
    "    def __init__(self, power=2, **kwargs):\n",
    "        super().__init__()\n",
    "        self.r = Displacement(**kwargs)\n",
    "        self.p = power\n",
    "\n",
    "    def forward(self, true_norm=False, **kwargs):\n",
    "        norm = (self.r(**kwargs).abs().pow(self.p)).sum(dim=-1)\n",
    "        if true_norm:\n",
    "            norm = norm**(1.0/self.p)\n",
    "        return norm\n",
    "\n",
    "\n",
    "class Stationary(Module):\n",
    "    \"\"\" [p=2, dim=1] \"\"\"\n",
    "\n",
    "    def __init__(self, signal=torch.ones(1), **kwargs):\n",
    "        super().__init__()\n",
    "        self.rp = PNorm(**kwargs)\n",
    "        self._signal = Parameter(free_form(torch.as_tensor(signal)))\n",
    "\n",
    "    def forward(self, x=None, xx=None):\n",
    "        return positive(self._signal).pow(2)*self.cov_func(self.rp(x=x, xx=xx))\n",
    "\n",
    "    def cov_func(self, rp):\n",
    "        \"\"\" if r=0 it should return 1 \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'This should be implemented in a child class!')\n",
    "\n",
    "    def diag(self, x=None):\n",
    "        if x is None:\n",
    "            return positive(self._signal).pow(2)\n",
    "        else:\n",
    "            return positive(self._signal).pow(2)*torch.ones(x.size(0))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        print('signal variance: {}'.format(positive(self._signal).pow(2)))\n",
    "\n",
    "\n",
    "class SquaredExp(Stationary):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(power=2, **kwargs)\n",
    "\n",
    "    def cov_func(self, rp):\n",
    "        return (-rp/2).exp()\n",
    "\n",
    "\n",
    "class White(Stationary):\n",
    "\n",
    "    def __init__(self, signal=1e-3, **kwargs):\n",
    "        super().__init__(signal=signal, **kwargs)\n",
    "\n",
    "    def forward(self, x=None, xx=None):\n",
    "        x_in = x is not None\n",
    "        xx_in = xx is not None\n",
    "        if not x_in and not xx_in:\n",
    "            return self.diag()\n",
    "        elif x_in and not xx_in:\n",
    "            return self.diag(x).diag()\n",
    "        elif xx_in and not x_in:\n",
    "            return self.diag(xx).diag()\n",
    "        elif x_in and xx_in:\n",
    "            if x.shape == xx.shape and torch.allclose(x, xx):\n",
    "                return self.diag(x).diag()\n",
    "            else:\n",
    "                return torch.zeros(x.size(0), xx.size(0))\n",
    "\n",
    "\n",
    "def test():\n",
    "    if 1:\n",
    "        r = PNorm(dim=1, power=torch.rand(1))\n",
    "        x = torch.tensor([[0.0], [1.]])\n",
    "        assert (r(x=x, true_norm=True) == r(xx=x, true_norm=True)).all()\n",
    "        assert (r(x=x, true_norm=True) == torch.tensor(\n",
    "            [[0.0, 1.0], [1.0, 0.0]])).all()\n",
    "\n",
    "    if 1:\n",
    "        dim = 7\n",
    "        kern = SquaredExp(dim=dim)\n",
    "        x = torch.rand(19, dim)\n",
    "        xx = torch.rand(37, dim)\n",
    "        K = kern(x=x, xx=xx)\n",
    "        assert torch.allclose(K, (-(x[:, None]-xx[None])**2/2)\n",
    "                              .sum(dim=-1).exp())\n",
    "\n",
    "    if 1:\n",
    "        white = White(signal=1.0)\n",
    "        x = torch.rand(7, 1)\n",
    "        assert (white(x, x) == torch.eye(7)).all()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
