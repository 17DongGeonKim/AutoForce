{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theforce.similarity.similarity import SimilarityKernel\n",
    "from torch import zeros, cat, stack\n",
    "from theforce.util.util import iterable\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "\n",
    "class PairSimilarityKernel(SimilarityKernel):\n",
    "\n",
    "    def __init__(self, kernels, a, b):\n",
    "        super().__init__([kern for kern in iterable(kernels)])\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return super().state_args + ', {}, {}'.format(self.a, self.b)\n",
    "\n",
    "    def descriptor(self, r):\n",
    "        raise NotImplementedError(\n",
    "            'descriptor shoud be implemented in a child class')\n",
    "\n",
    "    def save_for_later(self, loc, keyvals):\n",
    "        for key, val in keyvals.items():\n",
    "            setattr(loc, self.name+'_'+key, val)\n",
    "\n",
    "    def saved(self, atoms_or_loc, key):\n",
    "        return getattr(atoms_or_loc, self.name+'_'+key)\n",
    "\n",
    "    def calculate(self, loc):\n",
    "        loc.select(self.a, self.b, bothways=True)\n",
    "        d, grad = self.descriptor(loc.r)\n",
    "        data = {'diag_value': d, 'diag_grad': grad}\n",
    "        self.save_for_later(loc, data)\n",
    "        m = (loc.j > loc.i)\n",
    "        if self.a == self.b:\n",
    "            m = m | ((loc.j == loc.i) & loc.lex)\n",
    "        data = {'value': d[m], 'grad': grad[m], 'i': loc.i[m], 'j': loc.j[m]}\n",
    "        self.save_for_later(loc, data)\n",
    "        if hasattr(self, 'factor'):\n",
    "            fac, facgrad = self.factor(d)\n",
    "            self.save_for_later(loc, {'diag_fac': fac, 'diag_facgrad': facgrad,\n",
    "                                      'fac': fac[m], 'facgrad': facgrad[m]})\n",
    "            self.has_factor = True\n",
    "        else:\n",
    "            self.has_factor = False\n",
    "\n",
    "    def func(self, p, q):\n",
    "        d = self.saved(p, 'value')\n",
    "        dd = self.saved(q, 'value')\n",
    "        c = self.kern(d, dd)\n",
    "        if self.has_factor:\n",
    "            f = self.saved(p, 'fac')\n",
    "            ff = self.saved(q, 'fac')\n",
    "            c = c * (f*ff.t())\n",
    "        return c.sum().view(1, 1)\n",
    "\n",
    "    def leftgrad(self, p, q):\n",
    "        d = self.saved(p, 'value')\n",
    "        grad = self.saved(p, 'grad')\n",
    "        i = self.saved(p, 'i')\n",
    "        j = self.saved(p, 'j')\n",
    "        dd = self.saved(q, 'value')\n",
    "        c = self.kern.leftgrad(d, dd)\n",
    "        if self.has_factor:\n",
    "            f = self.saved(p, 'fac')\n",
    "            fg = self.saved(p, 'facgrad')\n",
    "            ff = self.saved(q, 'fac')\n",
    "            c = c*(f*ff.t()) + (fg*ff.t())*self.kern(d, dd)\n",
    "        c = c[:, None] * grad[..., None]\n",
    "        c = c.sum(dim=-1).view(-1, 3)\n",
    "        g = zeros(p.natoms, 3).index_add(0, i, -c).index_add(0, j, c)\n",
    "        return g.view(-1, 1)\n",
    "\n",
    "    def rightgrad(self, p, q):\n",
    "        d = self.saved(p, 'value')\n",
    "        dd = self.saved(q, 'value')\n",
    "        grad = self.saved(q, 'grad')\n",
    "        i = self.saved(q, 'i')\n",
    "        j = self.saved(q, 'j')\n",
    "        c = self.kern.rightgrad(d, dd)\n",
    "        if self.has_factor:\n",
    "            f = self.saved(p, 'fac')\n",
    "            ff = self.saved(q, 'fac')\n",
    "            ffg = self.saved(q, 'facgrad')\n",
    "            c = c*(f*ff.t()) + (f*ffg.t())*self.kern(d, dd)\n",
    "        c = c[..., None] * grad\n",
    "        c = c.sum(dim=0).view(-1, 3)\n",
    "        g = zeros(q.natoms, 3).index_add(0, i, -c).index_add(0, j, c)\n",
    "        return g.view(1, -1)\n",
    "\n",
    "    def gradgrad(self, p, q):\n",
    "        raise NotImplementedError('Not defined yet')\n",
    "\n",
    "    def gradgraddiag(self, p):\n",
    "        forces = []\n",
    "        for i, loc in enumerate(iterable(p.loc)):\n",
    "            d = self.saved(loc, 'diag_value')\n",
    "            grad = self.saved(loc, 'diag_grad')\n",
    "            c = self.kern.gradgrad(d, d)\n",
    "            if self.has_factor:\n",
    "                f = self.saved(loc, 'diag_fac')\n",
    "                fg = self.saved(loc, 'diag_facgrad')\n",
    "                c = (c*(f*f.t()) + fg*fg.t()*self.kern(d, d) +\n",
    "                     (fg*f.t()*self.kern.rightgrad(d, d)) +\n",
    "                     (f*fg.t()*self.kern.leftgrad(d, d)))\n",
    "            c = c[..., None] * grad[None, ] * grad[:, None]\n",
    "            c = c.sum(dim=(0, 1))\n",
    "            forces += [c]\n",
    "        forces = cat(forces)\n",
    "        return forces.view(-1)\n",
    "\n",
    "\n",
    "class DistanceKernel(PairSimilarityKernel):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "\n",
    "    def descriptor(self, r):\n",
    "        d = (r**2).sum(dim=-1).sqrt().view(-1, 1)\n",
    "        grad = r/d\n",
    "        return d, grad\n",
    "\n",
    "\n",
    "class LogDistanceKernel(PairSimilarityKernel):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(*args)\n",
    "\n",
    "    def descriptor(self, r):\n",
    "        d = (r**2).sum(dim=-1).sqrt().view(-1, 1)\n",
    "        grad = r/d**2\n",
    "        return d.log(), grad\n",
    "\n",
    "\n",
    "class RepulsiveCoreKernel(DistanceKernel):\n",
    "    def __init__(self, *args, eta=1):\n",
    "        super().__init__(*args)\n",
    "        self.eta = eta\n",
    "\n",
    "    def factor(self, d):\n",
    "        return 1./d**self.eta, -self.eta/d**(self.eta+1)\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return super().state_args + ', eta={}'.format(self.eta)\n",
    "\n",
    "\n",
    "class PairKernel(DistanceKernel):\n",
    "    def __init__(self, *args, factor=None):\n",
    "        super().__init__(*args)\n",
    "        if factor is not None:\n",
    "            self.factor = factor\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return super().state_args + ', factor={}'.format(self.factor.state)\n",
    "\n",
    "\n",
    "class PairCut(Module):\n",
    "\n",
    "    def __init__(self, cutoff):\n",
    "        super().__init__()\n",
    "        self.rc = cutoff\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return '{}'.format(self.rc)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "    def forward(self, d):\n",
    "        step = torch.where(d < self.rc, torch.ones_like(d),\n",
    "                           torch.zeros_like(d))\n",
    "        f, g = self.func_and_grad(d)\n",
    "        return step*f, step*g\n",
    "\n",
    "    def func_and_grad(self, d):\n",
    "        raise NotImplementedError('func_and_grad')\n",
    "\n",
    "\n",
    "class PolyCut(PairCut):\n",
    "\n",
    "    def __init__(self, cutoff, n=2):\n",
    "        super().__init__(cutoff)\n",
    "        self.n = n\n",
    "\n",
    "    def func_and_grad(self, d):\n",
    "        return (d-self.rc)**self.n, self.n*(d-self.rc)**(self.n-1)\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return super().state_args + ', n={}'.format(self.n)\n",
    "\n",
    "\n",
    "class RepulsiveCore(Module):\n",
    "\n",
    "    def __init__(self, eta=1):\n",
    "        super().__init__()\n",
    "        self.eta = eta\n",
    "\n",
    "    def forward(self, d):\n",
    "        return 1./d**self.eta, -self.eta/d**(self.eta+1)\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return 'eta={}'.format(self.eta)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "\n",
    "class Product(Module):\n",
    "\n",
    "    def __init__(self, f, g):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "\n",
    "    def forward(self, d):\n",
    "        f, df = self.f(d)\n",
    "        g, dg = self.g(d)\n",
    "        return f*g, df*g + f*dg\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return '{}, {}'.format(self.f.state, self.g.state)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "\n",
    "def example():\n",
    "    from torch import tensor\n",
    "    from theforce.regression.core import SquaredExp\n",
    "\n",
    "    factor = Product(PolyCut(1.0), RepulsiveCore(12))\n",
    "    kern = PairKernel(SquaredExp(), 1, 1, factor=factor)\n",
    "    k = eval(kern.state)\n",
    "    d = torch.arange(0.1, 1.5, 0.1).view(-1)\n",
    "    d.requires_grad = True\n",
    "    f = eval(factor.state)\n",
    "    a, b = f(d)\n",
    "    a.sum().backward()\n",
    "    print(d.grad.allclose(b))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
