{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def read_params(**kwargs):\n",
    "\n",
    "    # default params\n",
    "    params = {\n",
    "        # gp\n",
    "        'numbers': None,\n",
    "        'cutoff': None,\n",
    "        'atomic_unit': None,\n",
    "        'lmax': 2,\n",
    "        'nmax': 2,\n",
    "        'exponent': 4,\n",
    "        'pairkernel': True,\n",
    "        'soapkernel': True,\n",
    "        'error': 0.05,\n",
    "        # data\n",
    "        'path_data': None,\n",
    "        'path_data_chp': None,\n",
    "        'path_inducing_chp': None,\n",
    "        'path_gp_chp': 'gp.chp',\n",
    "        'ndata': -1,\n",
    "        'nlocals': -1,\n",
    "        # other\n",
    "        'path_log': 'log.txt',\n",
    "        'test': False\n",
    "    }\n",
    "\n",
    "    # read param.txt if it exists\n",
    "    if os.path.isfile('param.txt'):\n",
    "        with open('params.txt') as file:\n",
    "            for line in file.readlines():\n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                a, b = (_s.strip() for _s in line.strip().split(':'))\n",
    "                if a not in params:\n",
    "                    raise RuntimeWarning(\n",
    "                        'params.txt: keyword {} is not recognized'.format(a))\n",
    "                    continue\n",
    "                if a.startswith('path'):\n",
    "                    params[a] = b\n",
    "                else:\n",
    "                    params[a] = eval('{}'.format(b))\n",
    "\n",
    "    # read kwargs\n",
    "    for a, b in kwargs.items():\n",
    "        if a not in params:\n",
    "            raise RuntimeWarning(\n",
    "                'kwargs: keyword {} is not recognized'.format(a))\n",
    "            continue\n",
    "        params[a] = b\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def potential_energy_surface(data=None, inducing=None, train=0, append_log=True, **kwargs):\n",
    "    from theforce.descriptor.atoms import AtomsData, LocalsData, sample_atoms\n",
    "    from theforce.regression.gppotential import GaussianProcessPotential\n",
    "    from theforce.regression.gppotential import PosteriorPotential\n",
    "    from theforce.regression.gppotential import train_gpp\n",
    "    from theforce.similarity.pair import PairKernel\n",
    "    from theforce.similarity.soap import SoapKernel\n",
    "    from theforce.regression.stationary import RBF\n",
    "    from theforce.math.cutoff import PolyCut\n",
    "    from theforce.util.util import iterable\n",
    "    from theforce.regression.kernel import White, Positive, DotProd, Normed, Mul, Pow, Add\n",
    "    from torch import tensor\n",
    "\n",
    "    # read params\n",
    "    params = read_params(**kwargs)\n",
    "    log = open(params['path_log'], 'a' if append_log else 'w')\n",
    "    log.write('{} threads: {}\\n'.format(37*'*', torch.get_num_threads()))\n",
    "\n",
    "    # data\n",
    "    if data is None:\n",
    "        data = sample_atoms(params['path_data'], size=params['ndata'],\n",
    "                            chp=params['path_data_chp'])\n",
    "        data.update(cutoff=params['cutoff'])\n",
    "        natoms = sum([len(atoms) for atoms in data])\n",
    "        log.write('cutoff: {}\\npath_data: {}\\nndata: {} (={} locals)\\npath_data_chp: {}\\n'.format(\n",
    "            params['cutoff'], params['path_data'], params['ndata'], natoms, params['path_data_chp']))\n",
    "    else:\n",
    "        # if data is given as kwarg, it already should be cutoff-ed.\n",
    "        assert len(data[-1]) == data[-1].natoms\n",
    "        natoms = sum([len(atoms) for atoms in data])\n",
    "        log.write('ndata: {} (={} locals) (kwarg)\\n'.format(len(data), natoms))\n",
    "\n",
    "    # inducing\n",
    "    if inducing is None:\n",
    "        if params['nlocals'] == -1:\n",
    "            inducing = data.to_locals()\n",
    "            log.write('nlocals: {} (=-1)\\n'.format(len(inducing)))\n",
    "        else:\n",
    "            inducing = data.sample_locals(params['nlocals'])\n",
    "            log.write('nlocals: {}\\n'.format(params['nlocals']))\n",
    "    else:\n",
    "        log.write('nlocals: {} (kwarg)\\n'.format(len(inducing)))\n",
    "    if params['path_inducing_chp'] is not None:\n",
    "        inducing.to_traj(params['path_inducing_chp'])\n",
    "        log.write('path_inducing_chp: {}\\n'.format(\n",
    "            params['path_inducing_chp']))\n",
    "\n",
    "    # Gaussian Process\n",
    "    if params['path_gp_chp'] and os.path.isfile(params['path_gp_chp']):\n",
    "        with open(params['path_gp_chp'], 'r') as f:\n",
    "            gp = eval(f.readlines()[-1])\n",
    "            kerns = gp.kern.kernels\n",
    "        log.write('path_gp_chp: {} (read)\\n'.format(params['path_gp_chp']))\n",
    "    else:\n",
    "        # numbers and pairs\n",
    "        if params['numbers'] is None:\n",
    "            _num = set()\n",
    "            for atoms in data:\n",
    "                for n in set(atoms.numbers):\n",
    "                    _num.add(n)\n",
    "            numbers = sorted(list(_num))\n",
    "            params['numbers'] = numbers\n",
    "        pairs = ([(a, b) for a, b in itertools.combinations(numbers, 2)] +\n",
    "                 [(a, a) for a in numbers])\n",
    "        log.write('numbers: {}\\n'.format(params['numbers']))\n",
    "\n",
    "        # kerns\n",
    "        log.write('pairkernel: {}\\nsoapkernel: {}\\n'.format(\n",
    "            params['pairkernel'], params['soapkernel']))\n",
    "        kerns = []\n",
    "        if params['pairkernel']:\n",
    "            kerns += [PairKernel(RBF(), a, b, factor=PolyCut(params['cutoff']))\n",
    "                      for a, b in pairs]\n",
    "        if params['soapkernel']:\n",
    "            kerns += [SoapKernel(Positive(1.0, requires_grad=True)*Normed(DotProd()**params['exponent']),\n",
    "                                 atomic_number, params['numbers'], params['lmax'], params['nmax'],\n",
    "                                 PolyCut(params['cutoff']), atomic_unit=params['atomic_unit'])\n",
    "                      for atomic_number in params['numbers']]\n",
    "            log.write('lmax: {}\\n nmax: {}\\nexponent: {}\\natomic_unit: {}\\n'.format(\n",
    "                params['lmax'], params['nmax'], params['exponent'], params['atomic_unit']))\n",
    "\n",
    "        gp = GaussianProcessPotential(\n",
    "            kerns, noise=White(signal=params['error'], requires_grad=True))\n",
    "        if params['path_gp_chp']:\n",
    "            gp.to_file(params['path_gp_chp'], flag='initial state', mode='w')\n",
    "            log.write('path_gp_chp: {} (write)\\n'.format(\n",
    "                params['path_gp_chp']))\n",
    "    log.close()\n",
    "\n",
    "    # train\n",
    "    data.update(descriptors=kerns)\n",
    "    inducing.stage(kerns)\n",
    "    inducing.trainable = False  # TODO: this should be set inside Locals\n",
    "    state = 0\n",
    "    for steps in iterable(train):\n",
    "        train_gpp(gp, data, inducing=inducing, steps=steps,\n",
    "                  logprob_loss=True, cov_loss=False)\n",
    "        # save gp\n",
    "        state += steps\n",
    "        if state > 0 and params['path_gp_chp']:\n",
    "            gp.to_file(params['path_gp_chp'],\n",
    "                       flag='state: {}'.format(state))\n",
    "            with open('log.txt', 'a') as log:\n",
    "                log.write('path_gp_chp: {} (write, state={})\\n'.format(\n",
    "                    params['path_gp_chp'], state))\n",
    "\n",
    "        # save inducing\n",
    "        if inducing.trainable:\n",
    "            raise NotImplementedError(\n",
    "                'trainable inducing is not implemented yet!')\n",
    "    if state > 0:\n",
    "        with open('log.txt', 'a') as log:\n",
    "            log.write('\\ntrained for {} steps\\n'.format(state))\n",
    "\n",
    "    # create Posterior Potential\n",
    "    V = PosteriorPotential(gp, data, inducing)\n",
    "\n",
    "    # test\n",
    "    if params['test']:\n",
    "        data.set_per_atoms('predicted_energy', V(data, 'energy'))\n",
    "        data.set_per_atom('predicted_forces', V(data, 'forces'))\n",
    "        var_e = data.target_energy.var()\n",
    "        var_ee = (data.cat('predicted_energy') - data.target_energy).var()\n",
    "        R2_e = 1-var_ee/var_e\n",
    "        var_f = data.target_forces.var()\n",
    "        var_ff = (data.cat('predicted_forces') - data.target_forces).var()\n",
    "        R2_f = 1-var_ff/var_f\n",
    "        with open('log.txt', 'a') as log:\n",
    "            log.write('\\ntesting the model on the same data that created it:')\n",
    "            log.write('\\nenergy R2 score={}'.format(R2_e))\n",
    "            log.write('\\nforces R2 score={}\\n'.format(R2_f))\n",
    "\n",
    "    return V"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
