{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.md.verlet import VelocityVerlet\n",
    "from theforce.calculator.posterior import PosteriorVarianceCalculator\n",
    "from theforce.run.pes import potential_energy_surface\n",
    "from theforce.descriptor.atoms import TorchAtoms, AtomsData, LocalsData, sample_atoms\n",
    "from theforce.util.util import iterable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mlmd(ini_atoms, cutoff, au, dt, tolerance=0.1, pair=True, soap=True, ndata=10, max_steps=100,\n",
    "         itrain=10*[5], retrain=5*[5], retrain_every=100, pes=potential_energy_surface):\n",
    "    \"\"\" \n",
    "    ML-assisted-MD: a calculator must be attached to ini_atoms.\n",
    "    Rules of thumb:\n",
    "    Initial training (itrain) is crucial for correct approximation \n",
    "    of variances.\n",
    "    Hyper-parameters are sensitive to nlocals=len(inducing) thus \n",
    "    if you don't want to retrain gp every time the data is updated, \n",
    "    at least keep nlocals fixed.\n",
    "    \"\"\"\n",
    "\n",
    "    dftcalc = ini_atoms.get_calculator()\n",
    "\n",
    "    # run a short MD to gather some (dft) data\n",
    "    atoms = TorchAtoms(ase_atoms=ini_atoms.copy())\n",
    "    atoms.set_velocities(ini_atoms.get_velocities())\n",
    "    atoms.set_calculator(dftcalc)\n",
    "    dyn = VelocityVerlet(atoms, dt=dt, trajectory='md.traj', logfile='md.log')\n",
    "    md_step = ndata\n",
    "    dyn.run(md_step)\n",
    "    ndft = md_step\n",
    "\n",
    "    # train a potential\n",
    "    data = AtomsData(traj='md.traj', cutoff=cutoff)\n",
    "    inducing = data.to_locals()\n",
    "    V = pes(data=data, inducing=inducing, cutoff=cutoff, atomic_unit=au, pairkernel=pair,\n",
    "            soapkernel=soap, train=itrain, test=True, caching=True)\n",
    "    atoms.update(cutoff=cutoff, descriptors=V.gp.kern.kernels)\n",
    "    mlcalc = PosteriorVarianceCalculator(V)\n",
    "    atoms.set_calculator(mlcalc)\n",
    "\n",
    "    # long MD\n",
    "    while md_step < max_steps:\n",
    "\n",
    "        md_step += 1\n",
    "\n",
    "        forces = atoms.get_forces()\n",
    "        var = atoms.calc.results['forces_var']\n",
    "        tol = np.sqrt(var.max(axis=1))\n",
    "\n",
    "        if (tol > tolerance).any():\n",
    "\n",
    "            _forces = forces\n",
    "            _var = var\n",
    "\n",
    "            # new dft calculation\n",
    "            ndft += 1\n",
    "            print('|............... new dft calculation (total={})'.format(ndft))\n",
    "            tmp = atoms.copy()\n",
    "            tmp.set_calculator(dftcalc)\n",
    "            true_forces = tmp.get_forces()\n",
    "\n",
    "            # add new information to data\n",
    "            new_data = AtomsData(X=[TorchAtoms(ase_atoms=tmp)])\n",
    "            new_data.update(\n",
    "                cutoff=cutoff, descriptors=atoms.calc.potential.gp.kern.kernels)\n",
    "            new_locals = new_data.to_locals()\n",
    "            new_locals.stage(descriptors=atoms.calc.potential.gp.kern.kernels)\n",
    "            data += new_data\n",
    "            inducing += new_locals  # TODO: importance sampling\n",
    "\n",
    "            # remove old(est) information\n",
    "            del data.X[0]\n",
    "            del inducing.X[:len(new_locals)]  # TODO: importance sampling\n",
    "\n",
    "            # retrain\n",
    "            if ndft % retrain_every == 0:\n",
    "                print('|............... : retraining for {} steps'.format(retrain))\n",
    "                for steps in iterable(retrain):\n",
    "                    atoms.calc.potential.train(data, inducing=inducing,\n",
    "                                               steps=steps,  cov_loss=False)\n",
    "                    atoms.calc.potential.gp.to_file(\n",
    "                        'gp.chp', flag='ndft={}'.format(ndft))\n",
    "\n",
    "            # update model\n",
    "            print('|............... new regression')\n",
    "            atoms.calc.potential.set_data(data, inducing, use_caching=True)\n",
    "\n",
    "            # new forces\n",
    "            atoms.calc.results.clear()\n",
    "            forces = atoms.get_forces()\n",
    "            var = atoms.calc.results['forces_var']\n",
    "\n",
    "            # report\n",
    "            _err_pred = np.sqrt(_var).max()\n",
    "            _err = np.abs(_forces - true_forces).max()\n",
    "            err_pred = np.sqrt(var).max()\n",
    "            err = np.abs(forces - true_forces).max()\n",
    "            print(\n",
    "                '|............... : old max-error: predicted={}, true={}'.format(_err_pred, _err))\n",
    "            print(\n",
    "                '|............... : new max-error: predicted={}, true={}'.format(err_pred, err))\n",
    "            arrays = np.concatenate(\n",
    "                [true_forces, _forces, forces, _var, var], axis=1)\n",
    "            with open('forces_var.txt', 'ab') as report:\n",
    "                np.savetxt(report, arrays)\n",
    "\n",
    "        print(md_step, '_')\n",
    "        dyn.run(1)\n",
    "    print('finished {} steps, used dftcalc only {} times'.format(md_step, ndft))\n",
    "\n",
    "\n",
    "def example():\n",
    "    from ase.calculators.lj import LennardJones\n",
    "    from theforce.util.flake import Hex\n",
    "    from ase.io.trajectory import Trajectory\n",
    "    from ase.optimize import BFGSLineSearch\n",
    "    from ase.io import Trajectory\n",
    "\n",
    "    # initial state + dft calculator\n",
    "    ini_atoms = TorchAtoms(positions=Hex().array(), cutoff=3.0)\n",
    "    dftcalc = LennardJones()\n",
    "    ini_atoms.set_calculator(dftcalc)\n",
    "    BFGSLineSearch(ini_atoms).run(fmax=0.01)\n",
    "    vel = np.random.uniform(-1., 1., size=ini_atoms.positions.shape)*1.\n",
    "    vel -= vel.mean(axis=0)\n",
    "    ini_atoms.set_velocities(vel)\n",
    "\n",
    "    # use a pretrained model by writing it to the checkpoint\n",
    "    # (alternatively set, for example, itrain=10*[5] in mlmd)\n",
    "    pre = \"\"\"GaussianProcessPotential([PairKernel(RBF(signal=3.2251566545458794, lengthscale=tensor([0.1040])),\n",
    "    0, 0, factor=PolyCut(3.0, n=2))], White(signal=0.1064043798026091, requires_grad=True))\"\"\".replace('\\n', '')\n",
    "    with open('gp.chp', 'w') as chp:\n",
    "        chp.write(pre)\n",
    "\n",
    "    # run(md)\n",
    "    mlmd(ini_atoms, 3.0, 0.5, 0.03, tolerance=0.18, max_steps=100,\n",
    "         soap=False, itrain=10*[3], retrain_every=5, retrain=5)\n",
    "\n",
    "    # recalculate all with the actual calculator and compare\n",
    "    traj = Trajectory('md.traj')\n",
    "    energies = []\n",
    "    forces = []\n",
    "    dum = 0\n",
    "    for atoms in traj:\n",
    "        dum += 1\n",
    "        e = atoms.get_potential_energy()\n",
    "        f = atoms.get_forces()\n",
    "        dftcalc.calculate(atoms)\n",
    "        ee = dftcalc.results['energy']\n",
    "        ff = dftcalc.results['forces']\n",
    "        energies += [(e, ee)]\n",
    "        forces += [(f.reshape(-1), ff.reshape(-1))]\n",
    "\n",
    "    import pylab as plt\n",
    "    %matplotlib inline\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    axes[0].scatter(*zip(*energies))\n",
    "    axes[0].set_xlabel('ml')\n",
    "    axes[0].set_ylabel('dft')\n",
    "    a, b = (np.concatenate(v) for v in zip(*forces))\n",
    "    axes[1].scatter(a, b)\n",
    "    axes[1].set_xlabel('ml')\n",
    "    axes[1].set_ylabel('dft')\n",
    "    fig.tight_layout()\n",
    "    fig.text(0.2, 0.8, 'energy')\n",
    "    fig.text(0.7, 0.8, 'forces')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    os.system('rm -f log.txt gp.chp md.log md.traj forces_var.txt')\n",
    "    example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
