{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import ones_like, as_tensor, from_numpy, cat\n",
    "from ase.atoms import Atoms\n",
    "from ase.neighborlist import NeighborList\n",
    "from ase.calculators.calculator import PropertyNotImplementedError\n",
    "import copy\n",
    "\n",
    "\n",
    "def lex3(x):\n",
    "    if x[0] != 0:\n",
    "        return x[0] > -x[0]\n",
    "    elif x[1] != 0:\n",
    "        return x[1] > -x[1]\n",
    "    elif x[2] != 0:\n",
    "        return x[2] > -x[2]\n",
    "    else:\n",
    "        return True  # True or False here shouldn't make any difference\n",
    "\n",
    "\n",
    "class Local:\n",
    "\n",
    "    def __init__(self, i, j, a, b, r, off=None, descriptors=[]):\n",
    "        \"\"\"\n",
    "        i, j: indices\n",
    "        a, b: atomic numbers\n",
    "        r : r[j] - r[i]\n",
    "        off: offsets\n",
    "        \"\"\"\n",
    "        self._i = from_numpy(np.full_like(j, i))\n",
    "        self._j = from_numpy(j)\n",
    "        self._a = from_numpy(np.full_like(b, a))\n",
    "        self._b = from_numpy(b)\n",
    "        self._r = r\n",
    "        self._m = ones_like(self._i).to(torch.bool)\n",
    "        if off is None:\n",
    "            self._lex = ones_like(self._i).byte()\n",
    "        else:\n",
    "            self._lex = torch.tensor([lex3(a) for a in off]).byte()\n",
    "        self.loc = self\n",
    "        self.stage(descriptors)\n",
    "\n",
    "    def stage(self, descriptors):\n",
    "        for desc in descriptors:\n",
    "            desc.precalculate(self)\n",
    "\n",
    "    @property\n",
    "    def i(self):\n",
    "        return self._i[self._m]\n",
    "\n",
    "    @property\n",
    "    def j(self):\n",
    "        return self._j[self._m]\n",
    "\n",
    "    @property\n",
    "    def a(self):\n",
    "        return self._a[self._m]\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self._b[self._m]\n",
    "\n",
    "    @property\n",
    "    def r(self):\n",
    "        return self._r[self._m]\n",
    "\n",
    "    @property\n",
    "    def lex(self):\n",
    "        return self._lex[self._m]\n",
    "\n",
    "    def select(self, a, b, bothways=False, in_place=True):\n",
    "        m = (self._a == a) & (self._b == b)\n",
    "        if a == b:\n",
    "            if bothways:\n",
    "                pass\n",
    "            else:\n",
    "                m = m & ((self._j > self._i) | ((self._j == self._i) &\n",
    "                                                self._lex))\n",
    "        elif a != b:\n",
    "            if bothways:\n",
    "                m = (m | ((self._a == b) & (self._b == a)))\n",
    "            else:\n",
    "                pass\n",
    "        if in_place:\n",
    "            self._m = m.to(torch.bool)\n",
    "        return m.to(torch.bool)\n",
    "\n",
    "    def unselect(self):\n",
    "        self._m = ones_like(self._i).to(torch.bool)\n",
    "\n",
    "    def as_atoms(self):\n",
    "        atoms = (TorchAtoms(numbers=self._a.unique().detach().numpy(), positions=[(0, 0, 0)]) +\n",
    "                 TorchAtoms(numbers=self._b.detach().numpy(), positions=self._r.detach().numpy()))\n",
    "        return atoms\n",
    "\n",
    "    def detach(self, keepids=False):\n",
    "        a = self._a.detach().numpy()\n",
    "        b = self._b.detach().numpy()\n",
    "        r = self._r.clone()\n",
    "        if keepids:\n",
    "            i = self._i.detach().numpy()\n",
    "            j = self._j.detach().numpy()\n",
    "        else:\n",
    "            i = np.zeros(a.shape[0], dtype=np.int)\n",
    "            j = np.arange(1, a.shape[0]+1, dtype=np.int)\n",
    "        return Local(i, j, a, b, r)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return all([(self._i == other._i).all(), (self._j == other._j).all(),\n",
    "                    (self._a == other._a).all(), (self._b == other._b).all(),\n",
    "                    (self._r == other._r).all(), (self._lex == other._lex).all()])\n",
    "\n",
    "\n",
    "class AtomsChanges:\n",
    "\n",
    "    def __init__(self, atoms):\n",
    "        self._ref = atoms\n",
    "        self.update_references()\n",
    "\n",
    "    def update_references(self):\n",
    "        self._natoms = self._ref.natoms\n",
    "        self._numbers = self._ref.numbers.copy()\n",
    "        self._positions = self._ref.positions.copy()\n",
    "        self._cell = self._ref.cell.copy()\n",
    "        self._pbc = self._ref.pbc.copy()\n",
    "        self._descriptors = [kern.state for kern in\n",
    "                             self._ref.descriptors]\n",
    "\n",
    "    @property\n",
    "    def natoms(self):\n",
    "        return self._ref.natoms != self._natoms\n",
    "\n",
    "    @property\n",
    "    def atomic_numbers(self):\n",
    "        return (self._ref.numbers != self._numbers).any()\n",
    "\n",
    "    @property\n",
    "    def numbers(self):\n",
    "        return (self.natoms or self.atomic_numbers)\n",
    "\n",
    "    @property\n",
    "    def positions(self):\n",
    "        return not np.allclose(self._ref.positions, self._positions)\n",
    "\n",
    "    @property\n",
    "    def cell(self):\n",
    "        return not np.allclose(self._ref.cell, self._cell)\n",
    "\n",
    "    @property\n",
    "    def pbc(self):\n",
    "        return (self._ref.pbc != self._pbc).any()\n",
    "\n",
    "    @property\n",
    "    def atoms(self):\n",
    "        return any([self.numbers, self.positions, self.cell, self.pbc])\n",
    "\n",
    "    @property\n",
    "    def descriptors(self):\n",
    "        return [c != r.state for c, r in zip(*[self._descriptors, self._ref.descriptors])]\n",
    "\n",
    "\n",
    "class TorchAtoms(Atoms):\n",
    "\n",
    "    def __init__(self, ase_atoms=None, energy=None, forces=None, cutoff=None,\n",
    "                 descriptors=[], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if ase_atoms:\n",
    "            self.__dict__ = ase_atoms.__dict__\n",
    "\n",
    "        # ------------------------------- ----------\n",
    "        self.cutoff = cutoff\n",
    "        self.descriptors = descriptors\n",
    "        self.changes = AtomsChanges(self)\n",
    "        if cutoff is not None:\n",
    "            self.build_nl(cutoff)\n",
    "            self.update(forced=True)\n",
    "        # ------------------------------------------\n",
    "\n",
    "        try:\n",
    "            self.target_energy = as_tensor(energy)\n",
    "            self.target_forces = as_tensor(forces)\n",
    "        except RuntimeError:\n",
    "            if ase_atoms is not None and ase_atoms.get_calculator() is not None:\n",
    "                self.target_energy = as_tensor(\n",
    "                    ase_atoms.get_potential_energy())\n",
    "                self.target_forces = as_tensor(ase_atoms.get_forces())\n",
    "\n",
    "    def build_nl(self, rc):\n",
    "        self.nl = NeighborList(self.natoms * [rc / 2], skin=0.0,\n",
    "                               self_interaction=False, bothways=True)\n",
    "        self.cutoff = rc\n",
    "        self.xyz = torch.from_numpy(self.positions)\n",
    "        self.lll = torch.from_numpy(self.cell)\n",
    "\n",
    "    def update(self, cutoff=None, descriptors=None, forced=False,\n",
    "               posgrad=False, cellgrad=False):\n",
    "        if cutoff or self.changes.numbers:\n",
    "            self.build_nl(cutoff if cutoff else self.cutoff)\n",
    "            forced = True\n",
    "        if descriptors:\n",
    "            self.descriptors = descriptors\n",
    "            forced = True\n",
    "        if forced or self.changes.atoms:\n",
    "            self.nl.update(self)\n",
    "            self.loc = []\n",
    "            types = self.get_atomic_numbers()\n",
    "            self.xyz.requires_grad = posgrad\n",
    "            self.lll.requires_grad = cellgrad\n",
    "            for a in range(self.natoms):\n",
    "                n, off = self.nl.get_neighbors(a)\n",
    "                cells = (from_numpy(off[..., None].astype(np.float)) *\n",
    "                         self.lll).sum(dim=1)\n",
    "                r = self.xyz[n] - self.xyz[a] + cells\n",
    "                self.loc += [Local(a, n, types[a], types[n],\n",
    "                                   r, off, self.descriptors)]\n",
    "            for loc in self.loc:\n",
    "                loc.natoms = self.natoms\n",
    "\n",
    "            self.changes.update_references()\n",
    "\n",
    "    @property\n",
    "    def natoms(self):\n",
    "        return self.get_number_of_atoms()\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        try:\n",
    "            return torch.cat([env.__dict__[attr] for env in self.loc])\n",
    "        except KeyError:\n",
    "            raise AttributeError()\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"This is a overloads the behavior of ase.Atoms.\"\"\"\n",
    "        return self.loc[k]\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"This is a overloads the behavior of ase.Atoms.\"\"\"\n",
    "        for env in self.loc:\n",
    "            yield env\n",
    "\n",
    "    def copy(self):\n",
    "        new = TorchAtoms(positions=self.positions.copy(),\n",
    "                         cell=self.cell.copy(),\n",
    "                         numbers=self.numbers.copy(),\n",
    "                         pbc=self.pbc.copy(),\n",
    "                         descriptors=self.descriptors,\n",
    "                         cutoff=self.cutoff)\n",
    "        return new\n",
    "\n",
    "    def set_cell(self, *args, **kwargs):\n",
    "        super().set_cell(*args, **kwargs)\n",
    "        self.lll = torch.from_numpy(self.cell)\n",
    "\n",
    "    def set_positions(self, *args, **kwargs):\n",
    "        super().set_positions(*args, **kwargs)\n",
    "        self.xyz = torch.from_numpy(self.positions)\n",
    "\n",
    "    def as_ase(self):\n",
    "        atoms = Atoms(positions=self.positions, cell=self.cell,\n",
    "                      pbc=self.pbc, numbers=self.numbers)  # TODO: e, f\n",
    "        return atoms\n",
    "\n",
    "    def as_local(self):\n",
    "        \"\"\" As the inverse of Local.as_atoms \"\"\"\n",
    "        # positions[0] should to be [0, 0, 0]\n",
    "        r = torch.as_tensor(self.positions[1:])\n",
    "        a, b = np.broadcast_arrays(self.numbers[0], self.numbers[1:])\n",
    "        _i = np.arange(self.natoms)\n",
    "        i, j = np.broadcast_arrays(_i[0], _i[1:])\n",
    "        return Local(i, j, a, b, r)\n",
    "\n",
    "    def shake(self, beta=0.05, update=True):\n",
    "        trans = np.random.laplace(0., beta, size=self.positions.shape)\n",
    "        self.translate(trans)\n",
    "        if update:\n",
    "            self.update()\n",
    "\n",
    "\n",
    "class AtomsData:\n",
    "\n",
    "    def __init__(self, X=None, traj=None, posgrad=False, cellgrad=False, **kwargs):\n",
    "        if X:\n",
    "            self.X = X\n",
    "        elif traj:\n",
    "            self.X = []\n",
    "            from ase.io import Trajectory\n",
    "            t = Trajectory(traj, 'r')\n",
    "            self.X += [TorchAtoms(ase_atoms=atoms, **kwargs)\n",
    "                       for atoms in t]\n",
    "            t.close()\n",
    "        self._X = self.X\n",
    "        self.posgrad = posgrad\n",
    "        self.cellgrad = cellgrad\n",
    "\n",
    "    def apply(self, operation, *args, **kwargs):\n",
    "        for atoms in self.X:\n",
    "            getattr(atoms, operation)(*args, **kwargs)\n",
    "\n",
    "    def set_gpp(self, gpp, cutoff=None):\n",
    "        self.apply('update', cutoff=cutoff,\n",
    "                   descriptors=gpp.kern.kernels, forced=True)\n",
    "\n",
    "    def update_nl_if_requires_grad(self, descriptors=None, forced=False):\n",
    "        if self.trainable:\n",
    "            for atoms in self.X:\n",
    "                atoms.update(descriptors=descriptors, forced=forced,\n",
    "                             posgrad=self.posgrad, cellgrad=self.cellgrad)\n",
    "\n",
    "    def set_per_atoms(self, quant, values):\n",
    "        vals = torch.split(values, split_size_or_sections=1)\n",
    "        for atoms, v in zip(*[self, vals]):\n",
    "            setattr(atoms, quant, v)\n",
    "\n",
    "    def set_per_atom(self, quant, values):\n",
    "        vals = torch.split(values, split_size_or_sections=self.natoms)\n",
    "        for atoms, v in zip(*[self, vals]):\n",
    "            setattr(atoms, quant, v)\n",
    "\n",
    "    def shake(self, **kwargs):\n",
    "        for atoms in self.X:\n",
    "            atoms.shake(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def natoms(self):\n",
    "        return [atoms.natoms for atoms in self]\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [atoms.xyz for atoms in self.X if atoms.xyz.requires_grad]\n",
    "\n",
    "    @property\n",
    "    def trainable(self):\n",
    "        return self.posgrad or self.cellgrad\n",
    "\n",
    "    @property\n",
    "    def target_energy(self):\n",
    "        return torch.tensor([atoms.target_energy for atoms in self])\n",
    "\n",
    "    @property\n",
    "    def target_forces(self):\n",
    "        return torch.cat([atoms.target_forces for atoms in self])\n",
    "\n",
    "    def cat(self, attr):\n",
    "        return torch.cat([getattr(atoms, attr) for atoms in self])\n",
    "\n",
    "    def __iter__(self):\n",
    "        for atoms in self.X:\n",
    "            yield atoms\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        return self.X[k]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def atoms_to_firstloc(self):\n",
    "        self.X = [atoms[0].detach() for atoms in self.X]\n",
    "\n",
    "    def firstloc_to_atoms(self):\n",
    "        self.X = [loc.as_atoms() for loc in self.X]\n",
    "\n",
    "    def to_traj(self, trajname, mode='w'):\n",
    "        from ase.io import Trajectory\n",
    "        t = Trajectory(trajname, mode)\n",
    "        for atoms in self:\n",
    "            t.write(atoms)\n",
    "        t.close()\n",
    "\n",
    "    def pick_random(self, n):\n",
    "        self.X = [self._X[k] for k in torch.randperm(len(self._X))[:n]]\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if other.__class__ == AtomsData:\n",
    "            return AtomsData(X=self.X+other.X)\n",
    "        elif other.__class__ == TorchAtoms or other.__class__ == Local:\n",
    "            return AtomsData(X=self.X+[other])\n",
    "        elif other.__class__ == list:\n",
    "            return AtomsData(X=self.X+other)\n",
    "\n",
    "\n",
    "def diatomic(numbers, distances, pbc=False, cell=None):\n",
    "    from theforce.util.util import iterable\n",
    "    from itertools import combinations\n",
    "    if not hasattr(numbers[0], '__iter__'):\n",
    "        nums = ([(a, b) for a, b in combinations(set(numbers), 2)] +\n",
    "                [(a, a) for a in set(numbers)])\n",
    "    else:\n",
    "        nums = numbers\n",
    "    X = [TorchAtoms(positions=[[0., 0., 0.], [d, 0., 0.]], numbers=n, cell=cell, pbc=pbc)\n",
    "         for n in nums for d in iterable(distances)]\n",
    "    if len(X) > 1:\n",
    "        return AtomsData(X=X)\n",
    "    else:\n",
    "        return X[0]\n",
    "\n",
    "\n",
    "def namethem(descriptors, base='D'):\n",
    "    for i, desc in enumerate(descriptors):\n",
    "        desc.name = base+'_{}'.format(i)\n",
    "\n",
    "\n",
    "def example():\n",
    "    from theforce.similarity.pair import DistanceKernel\n",
    "    from theforce.regression.core import SquaredExp\n",
    "\n",
    "    kerns = [DistanceKernel(SquaredExp(), 10, 10),\n",
    "             DistanceKernel(SquaredExp(), 10, 18),\n",
    "             DistanceKernel(SquaredExp(), 18, 18)]\n",
    "    namethem(kerns)\n",
    "    xyz = np.stack(np.meshgrid([0, 1.5], [0, 1.5], [0, 1.5])\n",
    "                   ).reshape(3, -1).transpose()\n",
    "    numbers = 4*[10] + 4*[18]\n",
    "    atoms = TorchAtoms(positions=xyz, numbers=numbers,\n",
    "                       cutoff=3.0, descriptors=kerns)\n",
    "    atoms.copy()\n",
    "\n",
    "    for loc in atoms:\n",
    "        print(loc.as_atoms().as_local() == loc.detach())\n",
    "\n",
    "    empty = TorchAtoms(positions=[(0, 0, 0)], cutoff=3.)\n",
    "    empty[0].detach()._r\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
