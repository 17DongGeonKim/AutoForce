{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules import Module\n",
    "from math import pi as math_pi\n",
    "pi = torch.tensor(math_pi)\n",
    "\n",
    "\n",
    "def split_and_rotate_tiny_if_too_close_to_zaxis(xyz, tiny_angle=1e-2):\n",
    "    \"\"\"\n",
    "    tiny_angle is chosen such that the calculated gradients (in Ylm) are \n",
    "    consistent with torch.autograd.\n",
    "    This depends both on precision and scale of xyz.\n",
    "    \"\"\"\n",
    "    tol = tiny_angle*xyz[:, 2].abs()\n",
    "    if ((xyz[:, 0].abs() < tol) & (xyz[:, 1].abs() < tol)).any():\n",
    "        x = xyz[:, 0]\n",
    "        y = xyz[:, 1] - tiny_angle*xyz[:, 2]\n",
    "        z = tiny_angle*xyz[:, 1] + xyz[:, 2]\n",
    "        return x, y, z, tiny_angle\n",
    "    else:\n",
    "        return xyz[:, 0], xyz[:, 1], xyz[:, 2], 0\n",
    "\n",
    "\n",
    "def cart_coord_to_trig(x, y, z):\n",
    "    rxy_sq = x*x + y*y\n",
    "    rxy = rxy_sq.sqrt()\n",
    "    r = (rxy_sq + z*z).sqrt()\n",
    "    sin_theta = rxy/r\n",
    "    cos_theta = z/r\n",
    "    sin_phi = y/rxy\n",
    "    cos_phi = x/rxy\n",
    "    return r, sin_theta, cos_theta, sin_phi, cos_phi\n",
    "\n",
    "\n",
    "def sph_vec_to_cart(sin_theta, cos_theta, sin_phi, cos_phi, F_r, F_theta, F_phi):\n",
    "    F_x = sin_theta * cos_phi * F_r + cos_theta * cos_phi * F_theta - sin_phi * F_phi\n",
    "    F_y = sin_theta * sin_phi * F_r + cos_theta * sin_phi * F_theta + cos_phi * F_phi\n",
    "    F_z = cos_theta * F_r - sin_theta * F_theta\n",
    "    return F_x, F_y, F_z\n",
    "\n",
    "\n",
    "class Ylm(Module):\n",
    "    \"\"\"\n",
    "    Calculates spherical harmonics from the Cartesian coordinates,\n",
    "    using pytorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lmax):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lmax = lmax\n",
    "\n",
    "        # pre-calculate\n",
    "        self.Yoo = torch.sqrt(1./(4*pi))\n",
    "        self.alp_al = 2*[[]] + [torch.tensor([torch.tensor((4.*l*l-1.)/(l*l-m*m)).sqrt()\n",
    "                                              for m in range(l-1)])[:, None]\n",
    "                                for l in range(2, lmax+1)]\n",
    "        self.alp_bl = 2*[[]] + [torch.tensor([-torch.tensor(((l-1.)**2-m*m)/(4*(l-1.)**2-1)).sqrt()\n",
    "                                              for m in range(l-1)])[:, None]\n",
    "                                for l in range(2, lmax+1)]\n",
    "        self.alp_cl = [torch.tensor(2.*l+1.).sqrt()\n",
    "                       for l in range(lmax+1)]\n",
    "        self.alp_dl = [[]] + [-torch.tensor(1.+1./(2.*l)).sqrt()\n",
    "                              for l in range(1, lmax+1)]\n",
    "\n",
    "        # indices: for traversing diagonals\n",
    "        self.I = [[l+k for l in range(lmax-k+1)] for k in range(lmax+1)]\n",
    "        self.J = [[l for l in range(lmax-k+1)] for k in range(lmax+1)]\n",
    "\n",
    "        # l,m tables\n",
    "        self.l = torch.tensor([[l for m in range(l)] +\n",
    "                               [m for m in range(l, self.lmax+1)]\n",
    "                               for l in range(self.lmax+1)])[:, :, None]\n",
    "        self.m = torch.zeros_like(self.l)\n",
    "        for m in range(self.lmax+1):\n",
    "            self.m[self.I[m], self.J[m]] = m\n",
    "            self.m[self.J[m], self.I[m]] = m\n",
    "\n",
    "        # lower triangle indices\n",
    "        one = torch.ones(lmax+1, lmax+1)\n",
    "        self.sign = (-torch.tril(one, diagonal=-1) +\n",
    "                     torch.triu(one))[..., None]\n",
    "\n",
    "        # l,m related coeffs\n",
    "        self.coef = (((self.l-self.m)*(self.l+self.m)*(2*self.l+1)).float()\n",
    "                     / (2*self.l-1).float())[1:, 1:].sqrt()\n",
    "\n",
    "        # floats\n",
    "        self.l_float = self.l.type(one.type())\n",
    "        self.m_float = self.m.type(one.type())\n",
    "        self.coef = self.coef.type(one.type())\n",
    "\n",
    "    def forward(self, xyz, with_r=None, grad=True, spherical_grads=False):\n",
    "        \"\"\"\n",
    "        Calculates Y = r**l * Ylm(theta, phi).\n",
    "        To eliminate r**l factor set with_r=1.\n",
    "        If grad=True, gradient of Y wrt xyz will be calculated.\n",
    "        The imaginary componenst are stored in the upper diagonal of array Y.\n",
    "        l = 0, ..., lmax\n",
    "        m = 0, ..., l\n",
    "        r: real part\n",
    "        i: imaginary part\n",
    "\n",
    "        with lmax=3 this arrangement looks like\n",
    "\n",
    "            0 1 2 3       0 1 2 3        r i i i\n",
    "        l = 1 1 2 3   m = 1 0 1 2    Y = r r i i\n",
    "            2 2 2 3       2 1 0 1        r r r i\n",
    "            3 3 3 3       3 2 1 0        r r r r\n",
    "\n",
    "        the full harmonic with l, m (m>0): Y[l,l-m] + 1.0j*Y[l-m,l]\n",
    "                                    (m=0): Y[l,l]\n",
    "        ------------------------------------------------------------\n",
    "        Note: if one of vectors becomes too close to z_axis, the entire system\n",
    "        will be rotated slightly, and in turn, the calculated gradients will be\n",
    "        rotated by an inverse rotation.\n",
    "        This way the returned gradients are consistent with torch.autograd.\n",
    "        \"\"\"\n",
    "        x, y, z, angle = split_and_rotate_tiny_if_too_close_to_zaxis(xyz)\n",
    "        r, sin_theta, cos_theta, sin_phi, cos_phi = cart_coord_to_trig(x, y, z)\n",
    "        _r = r if with_r is None else torch.as_tensor(with_r).type(xyz.type())\n",
    "        r2 = _r*_r\n",
    "        r_sin_theta = _r*sin_theta\n",
    "        r_cos_theta = _r*cos_theta\n",
    "        # Associated Legendre polynomials\n",
    "        alp = [[torch.full_like(sin_theta, self.Yoo)]]\n",
    "        for l in range(1, self.lmax+1):\n",
    "            alp += [[self.alp_al[l][m] * (r_cos_theta*alp[l-1][m] + r2*self.alp_bl[l][m] *\n",
    "                                          alp[l-2][m]) for m in range(l-1)]\n",
    "                    + [self.alp_cl[l] * r_cos_theta * alp[l-1][l-1]]\n",
    "                    + [self.alp_dl[l] * r_sin_theta * alp[l-1][l-1]]]\n",
    "        # sin, cos of m*phi\n",
    "        sin = [torch.zeros_like(sin_phi), sin_phi]\n",
    "        cos = [torch.ones_like(cos_phi), cos_phi]\n",
    "        for m in range(2, self.lmax+1):\n",
    "            s = sin_phi*cos[-1] + cos_phi*sin[-1]\n",
    "            c = cos_phi*cos[-1] - sin_phi*sin[-1]\n",
    "            sin += [s]\n",
    "            cos += [c]\n",
    "        # Spherical Harmonics\n",
    "        n = sin_theta.size(0)\n",
    "        Yr = torch.cat(\n",
    "            [torch.cat([(alp[l][m]*cos[m]).view(1, n) for m in range(l, -1, -1)] +\n",
    "                       [torch.zeros(self.lmax-l, n)]).view(self.lmax+1, 1, n) for l in range(self.lmax+1)\n",
    "             ], dim=1).permute(1, 0, 2)\n",
    "        Yi = torch.cat(\n",
    "            [torch.cat([(alp[l][m]*sin[m]).view(1, n) for m in range(l, -1, -1)] +\n",
    "                       [torch.zeros(self.lmax-l, n)]).view(self.lmax+1, 1, n) for l in range(self.lmax+1)\n",
    "             ], dim=1)\n",
    "        Y = Yr + Yi\n",
    "        # partial derivatives\n",
    "        if grad:\n",
    "            if with_r is None:\n",
    "                Y_r = self.l_float*Y/r\n",
    "            else:\n",
    "                Y_r = torch.zeros_like(Y)\n",
    "            Y_theta = cos_theta * self.l_float * Y / sin_theta\n",
    "            Y_theta[1:, 1:] -= _r * Y[:-1, :-1] * self.coef / sin_theta\n",
    "            Y_phi = Y.clone().permute(1, 0, 2) * self.sign * self.m_float\n",
    "            if spherical_grads:\n",
    "                return Y, torch.stack([Y_r, Y_theta, Y_phi], dim=-1)\n",
    "            else:\n",
    "                cart = sph_vec_to_cart(sin_theta, cos_theta, sin_phi, cos_phi, Y_r,\n",
    "                                       Y_theta/r, Y_phi/(r*sin_theta))\n",
    "                if angle > 0:\n",
    "                    dY = torch.stack(\n",
    "                        [cart[0], cart[1]+angle*cart[2], -angle*cart[1]+cart[2]], dim=-1)\n",
    "                else:\n",
    "                    dY = torch.stack(cart, dim=-1)\n",
    "                return Y, dY\n",
    "        else:\n",
    "            return Y\n",
    "\n",
    "\n",
    "def compare_with_numpy_version():\n",
    "    import numpy as np\n",
    "    from theforce.descriptor.sph_repr import sph_repr\n",
    "    # torch.set_default_dtype(torch.double)\n",
    "    # torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "    lmax = 4\n",
    "    sph_np = sph_repr(lmax)\n",
    "    sph_torch = Ylm(lmax)\n",
    "\n",
    "    n = 7\n",
    "    xyz = torch.rand(n, 3, requires_grad=True)\n",
    "    x, y, z = (a.detach().numpy().reshape(-1) for a in xyz.split(1, dim=-1))\n",
    "\n",
    "    # test without r^l\n",
    "    r, sin_theta, cos_theta, sin_phi, cos_phi, Y_np = sph_np.ylm(x, y, z)\n",
    "    Y_theta_np, Y_phi_np = sph_np.ylm_partials(\n",
    "        sin_theta, cos_theta, Y_np, with_r=None)\n",
    "    Y, grads = sph_torch(xyz, with_r=1, spherical_grads=True)\n",
    "    Y_r, Y_theta, Y_phi = grads[..., 0], grads[..., 1], grads[..., 2]\n",
    "    a = Y.allclose(torch.tensor(Y_np).type(xyz.type()))\n",
    "    b = Y_theta.allclose(torch.tensor(Y_theta_np).type(xyz.type()))\n",
    "    c = Y_phi.allclose(torch.tensor(Y_phi_np).type(xyz.type()))\n",
    "    ea = (Y-torch.tensor(Y_np).type(xyz.type())).abs().max().data\n",
    "    eb = (Y_theta-torch.tensor(Y_theta_np).type(xyz.type())).abs().max().data\n",
    "    ec = (Y_phi-torch.tensor(Y_phi_np).type(xyz.type())).abs().max().data\n",
    "    print(a, b, c, ea, eb, ec)\n",
    "\n",
    "    # test with r^l\n",
    "    r, sin_theta, cos_theta, sin_phi, cos_phi, Y_np = sph_np.ylm_rl(x, y, z)\n",
    "    Y_theta_np, Y_phi_np = sph_np.ylm_partials(\n",
    "        sin_theta, cos_theta, Y_np, with_r=r)\n",
    "    Y, grads = sph_torch(xyz, with_r=None, spherical_grads=True)\n",
    "    Y_r, Y_theta, Y_phi = grads[..., 0], grads[..., 1], grads[..., 2]\n",
    "    a = Y.allclose(torch.tensor(Y_np).type(xyz.type()))\n",
    "    b = Y_theta.allclose(torch.tensor(Y_theta_np).type(xyz.type()))\n",
    "    c = Y_phi.allclose(torch.tensor(Y_phi_np).type(xyz.type()))\n",
    "    ea = (Y-torch.tensor(Y_np).type(xyz.type())).abs().max().data\n",
    "    eb = (Y_theta-torch.tensor(Y_theta_np).type(xyz.type())).abs().max().data\n",
    "    ec = (Y_phi-torch.tensor(Y_phi_np).type(xyz.type())).abs().max().data\n",
    "    print(a, b, c, ea, eb, ec)\n",
    "\n",
    "    Y.sum().backward(retain_graph=True)\n",
    "    Y_theta.sum().backward(retain_graph=True)\n",
    "    Y_phi.sum().backward()\n",
    "    xyz.grad\n",
    "\n",
    "\n",
    "def compare_grads_with_autograd():\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "    sph = Ylm(3)\n",
    "    xyz = torch.rand(10, 3, requires_grad=True)\n",
    "    Y, grad = sph(xyz, grad=True, with_r=1)\n",
    "    Y.sum().backward()\n",
    "    a = xyz.grad.allclose(grad.sum(dim=(0, 1)))\n",
    "    ea = (xyz.grad-grad.sum(dim=(0, 1))).abs().max().data\n",
    "    print(a, ea)\n",
    "\n",
    "    xyz = torch.rand(10, 3, requires_grad=True)\n",
    "    Y, grad = sph(xyz, grad=True, with_r=None)\n",
    "    Y.sum().backward()\n",
    "    a = xyz.grad.allclose(grad.sum(dim=(0, 1)))\n",
    "    ea = (xyz.grad-grad.sum(dim=(0, 1))).abs().max().data\n",
    "    print(a, ea)\n",
    "\n",
    "    xyz = torch.tensor([[0, 0, 1.0]], requires_grad=True)\n",
    "    Y, grad = sph(xyz, grad=True, with_r=None)\n",
    "    Y.sum().backward()\n",
    "    a = xyz.grad.allclose(grad.sum(dim=(0, 1)))\n",
    "    ea = (xyz.grad-grad.sum(dim=(0, 1))).abs().max().data\n",
    "    print(a, ea)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    compare_with_numpy_version()\n",
    "    compare_grads_with_autograd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
