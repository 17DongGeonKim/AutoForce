{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from theforce.math.ylm import Ylm\n",
    "from torch.nn import Module\n",
    "from math import factorial as fac\n",
    "\n",
    "\n",
    "class AbsSeriesSoap(Module):\n",
    "\n",
    "    def __init__(self, lmax, nmax, radial):\n",
    "        super().__init__()\n",
    "        self.ylm = Ylm(lmax)\n",
    "        self.nmax = nmax\n",
    "        self.radial = radial\n",
    "        one = torch.ones(lmax+1, lmax+1)\n",
    "        self.Yr = 2*torch.torch.tril(one) - torch.eye(lmax+1)\n",
    "        self.Yi = 2*torch.torch.triu(one, diagonal=1)\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return \"{}, {}, {}\".format(self.ylm.lmax, self.nmax, self.radial.state)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "    def forward(self, xyz, grad=True):\n",
    "        d = xyz.pow(2).sum(dim=-1).sqrt()\n",
    "        n = 2*torch.arange(self.nmax+1).type(xyz.type())\n",
    "        r, dr = self.radial(d)\n",
    "        f = (r*d[None]**n[:, None])\n",
    "        Y = self.ylm(xyz, grad=grad)\n",
    "        if grad:\n",
    "            Y, dY = Y\n",
    "        c = (f[:, None, None]*Y[None]).sum(dim=-1)\n",
    "        nnp = c[None, ]*c[:, None]\n",
    "        p = (nnp*self.Yr).sum(dim=-1) + (nnp*self.Yi).sum(dim=-2)\n",
    "        if grad:\n",
    "            df = dr*d[None]**n[:, None] + r*n[:, None]*d[None]**(n[:, None]-1)\n",
    "            df = df[..., None]*xyz/d[:, None]\n",
    "            dc = (df[:, None, None]*Y[None, ..., None] +\n",
    "                  f[:, None, None, :, None]*dY[None])\n",
    "            dnnp = (c[None, ..., None, None]*dc[:, None] +\n",
    "                    dc[None, ]*c[:, None, ..., None, None])\n",
    "            dp = ((dnnp*self.Yr[..., None, None]).sum(dim=-3) +\n",
    "                  (dnnp*self.Yi[..., None, None]).sum(dim=-4))\n",
    "            return p, dp\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "\n",
    "class SeriesSoap(Module):\n",
    "\n",
    "    def __init__(self, lmax, nmax, radial, scale=None, actual=False, normalize=False,\n",
    "                 cutcorners=0, symm=False):\n",
    "        super().__init__()\n",
    "        self.abs = AbsSeriesSoap(lmax, nmax, radial)\n",
    "\n",
    "        if scale:\n",
    "            self.scale = scale\n",
    "        else:\n",
    "            self.scale = radial.rc/3  # Note: a more thorough consideration is needed\n",
    "\n",
    "        if actual:\n",
    "            a = torch.tensor([[1./((2*l+1)*2**(2*n+l)*fac(n)*fac(n+l))\n",
    "                               for l in range(lmax+1)] for n in range(nmax+1)])\n",
    "            self.nnl = a[None]*a[:, None]\n",
    "        else:\n",
    "            self.nnl = torch.ones(nmax+1, nmax+1, lmax+1)\n",
    "\n",
    "        n = torch.arange(nmax+1)\n",
    "        self.mask = ((n[:, None]-n[None]).abs() <= nmax-cutcorners).byte()\n",
    "        if not symm:\n",
    "            self.mask = (self.mask & (n[:, None] >= n[None]).byte())\n",
    "\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.kwargs = 'actual={}, normalize={}, cutcorners={}, symm={}'.format(\n",
    "            actual, normalize, cutcorners, symm)\n",
    "\n",
    "    def forward(self, xyz, grad=True):\n",
    "        p = self.abs(xyz/self.scale, grad=grad)\n",
    "        if grad:\n",
    "            p, q = p\n",
    "            p = p*self.nnl\n",
    "            q = q*self.nnl[..., None, None]/self.scale\n",
    "\n",
    "        p = p[self.mask].view(-1)\n",
    "        if grad:\n",
    "            q = q[self.mask].view(p.size(0), *xyz.size())\n",
    "\n",
    "        if self.normalize:\n",
    "            norm = p.norm()\n",
    "            if norm > 0.0:\n",
    "                p = p/norm\n",
    "                if grad:\n",
    "                    q = q/norm\n",
    "                    q = q - p[..., None, None] * (p[..., None, None] * q\n",
    "                                                  ).sum(dim=(0))\n",
    "        if grad:\n",
    "            return p, q\n",
    "        else:\n",
    "            return p\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return \"{}, scale={}, {}\".format(\n",
    "            self.abs.state_args, self.scale, self.kwargs)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "\n",
    "def test_validity():\n",
    "    import torch\n",
    "    from theforce.math.cutoff import PolyCut\n",
    "\n",
    "    xyz = torch.tensor([[0.175, 0.884, -0.87, 0.354, -0.082, 3.1],\n",
    "                        [-0.791, 0.116, 0.19, -0.832, 0.184, 0.],\n",
    "                        [0.387, 0.761, 0.655, -0.528, 0.973, 0.]]).t()\n",
    "    xyz.requires_grad = True\n",
    "\n",
    "    target = torch.tensor([[[0.36174603, 0.39013356, 0.43448023],\n",
    "                            [0.39013356, 0.42074877, 0.46857549],\n",
    "                            [0.43448023, 0.46857549, 0.5218387]],\n",
    "\n",
    "                           [[0.2906253, 0.30558356, 0.33600938],\n",
    "                            [0.30558356, 0.3246583, 0.36077952],\n",
    "                            [0.33600938, 0.36077952, 0.40524778]],\n",
    "\n",
    "                           [[0.16241845, 0.18307552, 0.20443194],\n",
    "                            [0.18307552, 0.22340802, 0.26811937],\n",
    "                            [0.20443194, 0.26811937, 0.34109511]]])\n",
    "\n",
    "    s = AbsSeriesSoap(2, 2, PolyCut(3.0))\n",
    "    p, dp = s(xyz)\n",
    "    p = p.permute(2, 0, 1)\n",
    "    print('fits pre-calculated values: {}'.format(p.allclose(target)))\n",
    "\n",
    "    p.sum().backward()\n",
    "    print('fits gradients calculated by autograd: {}'.format(\n",
    "        xyz.grad.allclose(dp.sum(dim=(0, 1, 2)))))\n",
    "\n",
    "    # test with normalization turned on\n",
    "    s = SeriesSoap(3, 7, PolyCut(3.0), scale=1., normalize=True)\n",
    "    xyz.grad *= 0\n",
    "    p, dp = s(xyz)\n",
    "    p.sum().backward()\n",
    "    print('fits gradients calculated by autograd (normalize=True):{}'.format(\n",
    "        xyz.grad.allclose(dp.sum(dim=(0)))))\n",
    "\n",
    "    assert s.state == eval(s.state).state\n",
    "\n",
    "    # test if works with empty tensors\n",
    "    s(torch.rand(0, 3))\n",
    "\n",
    "\n",
    "def test_speed(N=100):\n",
    "    from theforce.math.cutoff import PolyCut\n",
    "    import time\n",
    "    s = AbsSeriesSoap(5, 5, PolyCut(3.0))\n",
    "    start = time.time()\n",
    "    for _ in range(N):\n",
    "        xyz = torch.rand(30, 3)\n",
    "        p = s(xyz)\n",
    "    finish = time.time()\n",
    "    delta = (finish-start)/N\n",
    "    print(\"speed of {}: {} sec\".format(s.state, delta))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_validity()\n",
    "    test_speed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
