{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "from theforce.regression.algebra import free_form, positive\n",
    "\n",
    "\n",
    "class RepulsiveCore(Module):\n",
    "\n",
    "    def __init__(self, eta=1):\n",
    "        super().__init__()\n",
    "        self.eta = eta\n",
    "\n",
    "    def forward(self, d, grad=True):\n",
    "        if grad:\n",
    "            return 1./d**self.eta, -self.eta/d**(self.eta+1)\n",
    "        else:\n",
    "            return 1./d**self.eta\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return 'eta={}'.format(self.eta)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "\n",
    "class ParamedRepulsiveCore(Module):\n",
    "\n",
    "    def __init__(self, z=1.0, lb=1.0, beta=1e-6):\n",
    "        \"\"\"z/r**eta where eta=lb+beta and beta>0\"\"\"\n",
    "        super().__init__()\n",
    "        assert beta > 0\n",
    "        self.z = z\n",
    "        self.lb = lb\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, d, grad=True):\n",
    "        if grad:\n",
    "            return self.z/d**self.eta, -self.eta*self.z/d**(self.eta+1)\n",
    "        else:\n",
    "            return self.z/d**self.eta\n",
    "\n",
    "    @property\n",
    "    def eta(self):\n",
    "        return self.lb + self.beta\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return positive(self._beta)\n",
    "\n",
    "    @beta.setter\n",
    "    def beta(self, value):\n",
    "        self._beta = Parameter(free_form(torch.as_tensor(value)))\n",
    "\n",
    "    @property\n",
    "    def z(self):\n",
    "        return self._z\n",
    "\n",
    "    @z.setter\n",
    "    def z(self, value):\n",
    "        self._z = Parameter(torch.as_tensor(value))\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        return [self._z, self._beta]\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return 'z={}, lb={}, beta={}'.format(self.z, self.lb, self.beta)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "\n",
    "class Product(Module):\n",
    "\n",
    "    def __init__(self, f, g):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "        self.params = []\n",
    "        for a in [f, g]:\n",
    "            if hasattr(a, 'params'):\n",
    "                self.params += a.params\n",
    "\n",
    "    def forward(self, d, grad=True):\n",
    "        f = self.f(d, grad=grad)\n",
    "        g = self.g(d, grad=grad)\n",
    "        if grad:\n",
    "            f, df = f\n",
    "            g, dg = g\n",
    "            return f*g, df*g + f*dg\n",
    "        else:\n",
    "            return f*g\n",
    "\n",
    "    @property\n",
    "    def state_args(self):\n",
    "        return '{}, {}'.format(self.f.state, self.g.state)\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.state_args)\n",
    "\n",
    "\n",
    "def example_optim():\n",
    "    from theforce.math.cutoff import PolyCut\n",
    "    cut = 1.63\n",
    "    d = torch.linspace(0.1, cut*1.3, 50).view(-1, 1)\n",
    "    Y = (3.7/d**2.4)*(1-d/cut)**2\n",
    "    fac = Product(ParamedRepulsiveCore(), PolyCut(cut))\n",
    "    optimizer = torch.optim.Adam([{'params': fac.params}], lr=0.5)\n",
    "\n",
    "    for _ in range(1000):\n",
    "        optimizer.zero_grad()\n",
    "        a, b = fac(d)\n",
    "        loss = ((a-Y)**2).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(fac.state)\n",
    "    print(fac.__class__.__name__)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    example_optim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
